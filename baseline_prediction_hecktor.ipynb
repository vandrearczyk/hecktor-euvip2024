{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNL7ntZtMNDSm8v5CILqIs+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vandrearczyk/hecktor-euvip2024/blob/main/baseline_prediction_hecktor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNtXSLS6meoA",
        "outputId": "4a5a56ed-3dae-471d-933f-0dc60e8f4f67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-survival in /usr/local/lib/python3.10/dist-packages (0.23.0)\n",
            "Requirement already satisfied: ecos in /usr/local/lib/python3.10/dist-packages (from scikit-survival) (2.0.14)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from scikit-survival) (1.4.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from scikit-survival) (2.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from scikit-survival) (1.26.4)\n",
            "Requirement already satisfied: osqp!=0.6.0,!=0.6.1 in /usr/local/lib/python3.10/dist-packages (from scikit-survival) (0.6.7.post0)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from scikit-survival) (2.1.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-survival) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn<1.6,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from scikit-survival) (1.5.1)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.10/dist-packages (from osqp!=0.6.0,!=0.6.1->scikit-survival) (0.1.7.post4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->scikit-survival) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->scikit-survival) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->scikit-survival) (2024.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.6,>=1.4.0->scikit-survival) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->scikit-survival) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install scikit-survival\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from sksurv.datasets import get_x_y\n",
        "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
        "from sksurv.ensemble import RandomSurvivalForest\n",
        "from sksurv.metrics import concordance_index_censored\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "from sklearn.utils import resample\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_features(folder_path, file_start=\"\"):\n",
        "    \"\"\"\n",
        "    Load all CSV files from a specified folder and concatenate them into a single DataFrame.\n",
        "\n",
        "    Args:\n",
        "    folder_path (str): Path to the folder containing CSV files.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: Combined DataFrame from all CSV files.\n",
        "    \"\"\"\n",
        "    dfs = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.startswith(file_start) and filename.endswith(\".csv\"):\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            df = pd.read_csv(file_path)\n",
        "            dfs.append(df)\n",
        "    combined_df = pd.concat(dfs, ignore_index=True)\n",
        "    return combined_df\n",
        "\n",
        "def preprocess_data(combined_df, prefixes=None):\n",
        "    \"\"\"\n",
        "    Preprocess the combined DataFrame by keeping the first three columns and those starting with specified prefixes.\n",
        "    Then pivot the table to combine 'Modality', 'ROI', and each feature.\n",
        "\n",
        "    Args:\n",
        "    combined_df (pd.DataFrame): Combined DataFrame from multiple CSV files.\n",
        "    prefixes (list of str or None): List of prefixes to keep in the DataFrame columns.\n",
        "                                    If None, all columns are retained.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: Pivoted DataFrame ready for model training.\n",
        "    \"\"\"\n",
        "    # Keep the first three columns\n",
        "    first_three_columns = combined_df.iloc[:, :3]\n",
        "\n",
        "    # If prefixes is None, keep all columns, otherwise filter columns by the specified prefixes\n",
        "    if prefixes is None:\n",
        "        filtered_df = combined_df\n",
        "    else:\n",
        "        filtered_columns = [col for col in combined_df.columns if any(col.startswith(prefix) for prefix in prefixes)]\n",
        "        filtered_df = pd.concat([first_three_columns, combined_df[filtered_columns]], axis=1)\n",
        "\n",
        "    # Melt the filtered DataFrame\n",
        "    feature_columns = [col for col in filtered_df.columns if col not in first_three_columns.columns]\n",
        "    melted_df = filtered_df.melt(id_vars=['PatientID', 'Modality', 'ROI'], value_vars=feature_columns, var_name='Feature')\n",
        "\n",
        "    # Create combined feature names\n",
        "    melted_df['Combined'] = melted_df['ROI'] + '_' + melted_df['Modality'] + '_' + melted_df['Feature']\n",
        "\n",
        "    # Pivot the DataFrame\n",
        "    pivoted_df = melted_df.pivot_table(index='PatientID', columns='Combined', values='value')\n",
        "    pivoted_df.reset_index(inplace=True)\n",
        "\n",
        "    print(\"Number of features: \", pivoted_df.shape[1])\n",
        "\n",
        "    return pivoted_df\n",
        "\n",
        "def filter_patients(pivoted_df, survival_df):\n",
        "    \"\"\"\n",
        "    Filter out patients not present in both the pivoted and survival DataFrames\n",
        "    based on the 'PatientID' column.\n",
        "\n",
        "    Args:\n",
        "    pivoted_df (pd.DataFrame): DataFrame containing patient features.\n",
        "    survival_df (pd.DataFrame): DataFrame containing patient survival data.\n",
        "\n",
        "    Returns:\n",
        "    tuple: A tuple containing the filtered pivoted_df and survival_df DataFrames.\n",
        "    \"\"\"\n",
        "\n",
        "    # Identify patients to be deleted from each DataFrame\n",
        "    deleted_from_survival = set(survival_df['PatientID']) - set(pivoted_df['PatientID'])\n",
        "    deleted_from_pivoted = set(pivoted_df['PatientID']) - set(survival_df['PatientID'])\n",
        "\n",
        "    # Print details of deleted patients\n",
        "    print(\"Deleted patients from survival_df:\", len(deleted_from_survival), deleted_from_survival)\n",
        "    print(\"Deleted patients from pivoted_df:\", len(deleted_from_pivoted), deleted_from_pivoted)\n",
        "\n",
        "    # Filter DataFrames to only include matching patients\n",
        "    pivoted_df = pivoted_df[pivoted_df['PatientID'].isin(survival_df['PatientID'])]\n",
        "    survival_df = survival_df[survival_df['PatientID'].isin(pivoted_df['PatientID'])]\n",
        "\n",
        "    # Print the number of remaining patients\n",
        "    print(\"Remaining patients:\", pivoted_df.shape[0])\n",
        "\n",
        "    return pivoted_df, survival_df\n",
        "\n",
        "def bootstrap_cindex(y_test, X_test, model, n_bootstraps=1000, random_state=42):\n",
        "    # Extract event and time data from y_test (assume y_test is a structured array or 2D array)\n",
        "    events = y_test['event']  # Assuming the first column is 'event'\n",
        "    times = y_test['time']   # Assuming the second column is 'time'\n",
        "\n",
        "    # Store all bootstrapped C-index values\n",
        "    cindex_values = []\n",
        "\n",
        "    # Set random seed for reproducibility\n",
        "    np.random.seed(random_state)\n",
        "\n",
        "    # Perform bootstrapping\n",
        "    for i in range(n_bootstraps):\n",
        "        # Sample with replacement from the test set\n",
        "        indices = resample(np.arange(len(y_test)), replace=True)\n",
        "        y_test_bootstrap = y_test[indices]\n",
        "        X_test_bootstrap = X_test[indices]\n",
        "\n",
        "        # Predict on the bootstrap sample\n",
        "        predictions = model.predict(X_test_bootstrap)\n",
        "\n",
        "        # Calculate C-index\n",
        "        cindex = concordance_index_censored(\n",
        "            y_test_bootstrap['event'],  # 'event' column\n",
        "            y_test_bootstrap['time'],  # 'time' column\n",
        "            predictions\n",
        "        )[0]\n",
        "\n",
        "        # Store the C-index value\n",
        "        cindex_values.append(cindex)\n",
        "\n",
        "    # Convert to a numpy array for easy statistical calculations\n",
        "    cindex_values = np.array(cindex_values)\n",
        "\n",
        "    # Calculate the mean C-index and confidence intervals\n",
        "    mean_cindex = np.mean(cindex_values)\n",
        "    ci_lower = np.percentile(cindex_values, 2.5)\n",
        "    ci_upper = np.percentile(cindex_values, 97.5)\n",
        "\n",
        "    return mean_cindex, ci_lower, ci_upper"
      ],
      "metadata": {
        "id": "oUJ8lUWbmhh4"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload features\n",
        "if any(fn.startswith('features_album') for fn in os.listdir('.')):\n",
        "  print('Features already uploaded')\n",
        "else:\n",
        "  uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fr1frdeYmia5",
        "outputId": "e07b7e24-2df1-47fc-cc65-16be531b1770"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features already uploaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload survival_data\n",
        "if os.path.exists('hecktor2022_endpoint_training.csv'):\n",
        "  print('Survival data already uploaded')\n",
        "else:\n",
        "  uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Sbz8K7rmk27",
        "outputId": "74ace084-fc16-4ae8-b017-db4bb37cc5c8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Survival data already uploaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lgig9UuXmmaU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d78efbd-b3e8-48d5-ebba-2f29eecc7a45"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of features:  79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the data\n",
        "features_df = load_features(folder_path='./', file_start=\"features_album\")\n",
        "pivoted_df = preprocess_data(features_df, prefixes=['original_intensity', 'original_SUV'])\n",
        "survival_df = pd.read_csv('hecktor2022_endpoint_training.csv')\n",
        "# Filter out patients if not present in features or survival data\n",
        "pivoted_df, survival_df = filter_patients(pivoted_df, survival_df)\n",
        "\n",
        "# Prepare data for training\n",
        "X = pivoted_df.drop(columns=['PatientID'])\n",
        "X = X.fillna(X.mean())\n",
        "y = np.array([(status, time) for status, time in zip(survival_df['Relapse'], survival_df['RFS'])],\n",
        "                dtype=[('event', 'bool'), ('time', 'float')])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature selection\n",
        "selector = SelectKBest(mutual_info_classif, k=10)  # Keep top 10 features\n",
        "X_train = selector.fit_transform(X_train, y_train['event'])\n",
        "X_test = selector.transform(X_test)\n",
        "print(\"Number of features after selection:\", X_test.shape[1])\n",
        "\n",
        "# Train the model\n",
        "model = RandomSurvivalForest(n_estimators=50, min_samples_split=20, min_samples_leaf=30, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "cindex_train = concordance_index_censored(y_train['event'], y_train['time'], model.predict(X_train))[0]\n",
        "cindex_test = concordance_index_censored(y_test['event'], y_test['time'], model.predict(X_test))[0]\n",
        "print(f'Concordance Index (Train): {cindex_train:.2f}')\n",
        "print(f'Concordance Index (Test): {cindex_test:.2f}')\n",
        "\n",
        "# Evaluate with boostrapping\n",
        "mean_cindex, ci_lower, ci_upper = bootstrap_cindex(y_test, X_test, model)\n",
        "print(f\"Bootstrap C-index: {mean_cindex:.3f} (95% CI: {ci_lower:.3f} - {ci_upper:.3f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "EzOXlV2DmrzL",
        "outputId": "1ecae887-1432-4740-9d87-0a10958a365f"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of features:  79\n",
            "Deleted patients from survival_df: 16 {'HMR-024', 'HMR-016', 'HGJ-074', 'MDA-001', 'CHUV-033', 'MDA-006', 'MDA-003', 'MDA-146', 'HMR-005', 'HMR-034', 'HMR-029', 'MDA-007', 'MDA-005', 'HGJ-073', 'CHUV-035', 'HMR-030'}\n",
            "Deleted patients from pivoted_df: 34 {'CHUP-025', 'CHUP-048', 'CHUP-041', 'CHUP-043', 'CHUP-027', 'CHUP-018', 'CHUP-062', 'CHUP-007', 'CHUP-069', 'CHUP-016', 'CHUP-055', 'CHUV-010', 'CHUV-007', 'CHUP-024', 'CHUP-012', 'CHUV-005', 'CHUP-049', 'CHUP-015', 'CHUV-003', 'CHUP-070', 'CHUP-033', 'CHUP-040', 'CHUP-039', 'CHUV-002', 'CHUP-050', 'CHUP-071', 'CHUV-011', 'CHUP-023', 'CHUP-005', 'CHUP-019', 'CHUV-008', 'CHUP-060', 'CHUP-004', 'CHUP-003'}\n",
            "Remaining patients: 472\n",
            "Concordance Index (Train): 0.81\n",
            "Concordance Index (Test): 0.53\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"None of [Index([51, 92, 14, 71, 60, 20, 82, 86, 74, 74, 87, 23,  2, 21, 52,  1, 87, 29,\\n       37,  1, 63, 59, 20, 32, 75, 57, 21, 88, 48, 90, 58, 41, 91, 59, 79, 14,\\n       61, 61, 46, 61, 50, 54, 63,  2, 50,  6, 20, 72, 38, 17,  3, 88, 59, 13,\\n        8, 89, 52,  1, 83, 91, 59, 70, 43,  7, 46, 34, 77, 80, 35, 49,  3,  1,\\n        5, 53,  3, 53, 92, 62, 17, 89, 43, 33, 73, 61, 13, 94, 47, 14, 71, 77,\\n       86, 61, 39, 84, 79],\\n      dtype='int64', name='Combined')] are in the [columns]\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-a20c36f63cd1>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Evaluate with boostrapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mmean_cindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mci_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mci_upper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbootstrap_cindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Bootstrap C-index: {mean_cindex:.3f} (95% CI: {ci_lower:.3f} - {ci_upper:.3f})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-3c4eee29820e>\u001b[0m in \u001b[0;36mbootstrap_cindex\u001b[0;34m(y_test, X_test, model, n_bootstraps, random_state)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0my_test_bootstrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mX_test_bootstrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;31m# Predict on the bootstrap sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3897\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3898\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3899\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3901\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6113\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6115\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6117\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6174\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6175\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6176\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6178\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index([51, 92, 14, 71, 60, 20, 82, 86, 74, 74, 87, 23,  2, 21, 52,  1, 87, 29,\\n       37,  1, 63, 59, 20, 32, 75, 57, 21, 88, 48, 90, 58, 41, 91, 59, 79, 14,\\n       61, 61, 46, 61, 50, 54, 63,  2, 50,  6, 20, 72, 38, 17,  3, 88, 59, 13,\\n        8, 89, 52,  1, 83, 91, 59, 70, 43,  7, 46, 34, 77, 80, 35, 49,  3,  1,\\n        5, 53,  3, 53, 92, 62, 17, 89, 43, 33, 73, 61, 13, 94, 47, 14, 71, 77,\\n       86, 61, 39, 84, 79],\\n      dtype='int64', name='Combined')] are in the [columns]\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train another model e.g. only with clinical info and compare them statistically\n",
        "\n",
        "# Load and preprocess the data\n",
        "features_df = load_features(folder_path='./', file_start=\"features_album\")\n",
        "pivoted_df = preprocess_data(features_df, prefixes=['original_glcm'])\n",
        "survival_df = pd.read_csv('hecktor2022_endpoint_training.csv')\n",
        "# Filter out patients if not present in features or survival data\n",
        "pivoted_df, survival_df = filter_patients(pivoted_df, survival_df)\n",
        "\n",
        "# Prepare data for training\n",
        "X2 = pivoted_df.drop(columns=['PatientID'])\n",
        "X2 = X2.fillna(X2.mean())\n",
        "y = np.array([(status, time) for status, time in zip(survival_df['Relapse'], survival_df['RFS'])],\n",
        "                dtype=[('event', 'bool'), ('time', 'float')])\n",
        "X_train2, X_test2, y_train, y_test = train_test_split(X2, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature selection\n",
        "selector = SelectKBest(mutual_info_classif, k=10)  # Keep top 10 features\n",
        "X_train2 = selector.fit_transform(X_train2, y_train['event'])\n",
        "X_test2 = selector.transform(X_test2)\n",
        "print(\"Number of features after selection:\", X_test2.shape[1])\n",
        "\n",
        "# Train the model\n",
        "# model2 = RandomSurvivalForest(n_estimators=100, min_samples_split=10, min_samples_leaf=15, random_state=42)\n",
        "model2 = RandomSurvivalForest(n_estimators=50, min_samples_split=20, min_samples_leaf=30, random_state=42)\n",
        "model2.fit(X_train2, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "cindex_train2 = concordance_index_censored(y_train['event'], y_train['time'], model2.predict(X_train2))[0]\n",
        "cindex_test2 = concordance_index_censored(y_test['event'], y_test['time'], model2.predict(X_test2))[0]\n",
        "print(f'Concordance Index (Train): {cindex_train2:.2f}')\n",
        "print(f'Concordance Index (Test): {cindex_test2:.2f}')\n",
        "\n",
        "# Evaluate with boostrapping\n",
        "mean_cindex, ci_lower, ci_upper = bootstrap_cindex(y_test, X_test2, model2)\n",
        "print(f\"Bootstrap C-index: {mean_cindex:.3f} (95% CI: {ci_lower:.3f} - {ci_upper:.3f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kf9n50MHmtcK",
        "outputId": "84b87f35-4708-4ed1-902a-283be078539d"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of features:  49\n",
            "Deleted patients from survival_df: 32 {'HMR-024', 'MDA-180', 'MDA-146', 'HMR-034', 'HMR-029', 'MDA-121', 'MDA-005', 'HMR-030', 'MDA-124', 'HGJ-074', 'MDA-001', 'CHUP-029', 'MDA-091', 'MDA-128', 'HGJ-073', 'MDA-003', 'MDA-029', 'MDA-192', 'HMR-016', 'MDA-201', 'MDA-048', 'CHUV-035', 'MDA-006', 'MDA-200', 'MDA-179', 'MDA-166', 'CHUV-033', 'CHUP-032', 'MDA-036', 'MDA-169', 'HMR-005', 'MDA-007'}\n",
            "Deleted patients from pivoted_df: 34 {'CHUP-025', 'CHUP-048', 'CHUP-041', 'CHUP-043', 'CHUP-027', 'CHUP-018', 'CHUP-062', 'CHUP-007', 'CHUP-069', 'CHUP-016', 'CHUP-055', 'CHUV-010', 'CHUV-007', 'CHUP-024', 'CHUP-012', 'CHUV-005', 'CHUP-049', 'CHUP-015', 'CHUV-003', 'CHUP-070', 'CHUP-033', 'CHUP-040', 'CHUP-039', 'CHUV-002', 'CHUP-050', 'CHUP-071', 'CHUV-011', 'CHUP-023', 'CHUP-005', 'CHUP-019', 'CHUV-008', 'CHUP-060', 'CHUP-004', 'CHUP-003'}\n",
            "Remaining patients: 456\n",
            "Number of features after selection: 10\n",
            "Concordance Index (Train): 0.78\n",
            "Concordance Index (Test): 0.51\n",
            "Bootstrap C-index: 0.503 (95% CI: 0.385 - 0.613)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate C-index\n",
        "def calculate_cindex(y_true, y_pred):\n",
        "    return concordance_index_censored(y_true['event'], y_true['time'], y_pred)[0]\n",
        "\n",
        "# Resample and compute differences\n",
        "def bootstrap_cindex_difference(X_test1, X_test2, y_test, model1, model2, n_iterations=1000):\n",
        "    differences = []\n",
        "    for _ in range(n_iterations):\n",
        "        X_resampled, y_resampled = resample(X_test1, y_test, random_state=_)\n",
        "        X_resampled2, y_resampled = resample(X_test2, y_test, random_state=_)\n",
        "        cindex1 = calculate_cindex(y_resampled, model1.predict(X_resampled))\n",
        "        cindex2 = calculate_cindex(y_resampled, model2.predict(X_resampled))\n",
        "        differences.append(cindex1 - cindex2)\n",
        "    return np.array(differences)\n",
        "\n",
        "# Compute the differences\n",
        "differences = bootstrap_cindex_difference(X_test, X_test2, y_test, model, model2)\n",
        "observed_diff = cindex_test - cindex_test2\n",
        "\n",
        "# Compute p-value\n",
        "p_value = np.mean(differences >= observed_diff)\n",
        "print(f'p-value: {p_value:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "iKGV0uYQmvIm",
        "outputId": "defcf595-bae0-4129-e6c6-08a7ab9437d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomSurvivalForest was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "X has 10 features, but RandomSurvivalForest is expecting 36 features as input.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-8f765cab6ea7>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Compute the differences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mdifferences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbootstrap_cindex_difference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mobserved_diff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcindex_test\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcindex_test2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-8f765cab6ea7>\u001b[0m in \u001b[0;36mbootstrap_cindex_difference\u001b[0;34m(X_test1, X_test2, y_test, model1, model2, n_iterations)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mX_resampled2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_resampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mcindex1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_cindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mcindex2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_cindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mdifferences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcindex1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcindex2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdifferences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sksurv/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0mrisk\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \"\"\"\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"predict\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_cumulative_hazard_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sksurv/ensemble/forest.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, predict_fn, X)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"estimators_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    639\u001b[0m             \u001b[0mforce_all_finite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    642\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    444\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: X has 10 features, but RandomSurvivalForest is expecting 36 features as input."
          ]
        }
      ]
    }
  ]
}