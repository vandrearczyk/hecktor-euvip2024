{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMquOEI1jnT9cly49x9p4du",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vandrearczyk/hecktor-euvip2024/blob/main/baseline_prediction_hecktor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNtXSLS6meoA"
      },
      "outputs": [],
      "source": [
        "! pip install scikit-survival\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from sksurv.datasets import get_x_y\n",
        "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
        "from sksurv.ensemble import RandomSurvivalForest\n",
        "from sksurv.metrics import concordance_index_censored\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_features(folder_path, file_start=\"\"):\n",
        "    \"\"\"\n",
        "    Load all CSV files from a specified folder and concatenate them into a single DataFrame.\n",
        "\n",
        "    Args:\n",
        "    folder_path (str): Path to the folder containing CSV files.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: Combined DataFrame from all CSV files.\n",
        "    \"\"\"\n",
        "    dfs = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.startswith(file_start) and filename.endswith(\".csv\"):\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            df = pd.read_csv(file_path)\n",
        "            dfs.append(df)\n",
        "    combined_df = pd.concat(dfs, ignore_index=True)\n",
        "    return combined_df\n",
        "\n",
        "def preprocess_data(combined_df, prefixes=None):\n",
        "    \"\"\"\n",
        "    Preprocess the combined DataFrame by keeping the first three columns and those starting with specified prefixes.\n",
        "    Then pivot the table to combine 'Modality', 'ROI', and each feature.\n",
        "\n",
        "    Args:\n",
        "    combined_df (pd.DataFrame): Combined DataFrame from multiple CSV files.\n",
        "    prefixes (list of str or None): List of prefixes to keep in the DataFrame columns.\n",
        "                                    If None, all columns are retained.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: Pivoted DataFrame ready for model training.\n",
        "    \"\"\"\n",
        "    # Keep the first three columns\n",
        "    first_three_columns = combined_df.iloc[:, :3]\n",
        "\n",
        "    # If prefixes is None, keep all columns, otherwise filter columns by the specified prefixes\n",
        "    if prefixes is None:\n",
        "        filtered_df = combined_df\n",
        "    else:\n",
        "        filtered_columns = [col for col in combined_df.columns if any(col.startswith(prefix) for prefix in prefixes)]\n",
        "        filtered_df = pd.concat([first_three_columns, combined_df[filtered_columns]], axis=1)\n",
        "\n",
        "    # Melt the filtered DataFrame\n",
        "    feature_columns = [col for col in filtered_df.columns if col not in first_three_columns.columns]\n",
        "    melted_df = filtered_df.melt(id_vars=['PatientID', 'Modality', 'ROI'], value_vars=feature_columns, var_name='Feature')\n",
        "\n",
        "    # Create combined feature names\n",
        "    melted_df['Combined'] = melted_df['ROI'] + '_' + melted_df['Modality'] + '_' + melted_df['Feature']\n",
        "\n",
        "    # Pivot the DataFrame\n",
        "    pivoted_df = melted_df.pivot_table(index='PatientID', columns='Combined', values='value')\n",
        "    pivoted_df.reset_index(inplace=True)\n",
        "\n",
        "    return pivoted_df"
      ],
      "metadata": {
        "id": "oUJ8lUWbmhh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload features\n",
        "if any(fn.startswith('features_album') for fn in os.listdir('.')):\n",
        "  print('Features already uploaded')\n",
        "else:\n",
        "  uploaded = files.upload()"
      ],
      "metadata": {
        "id": "fr1frdeYmia5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload survival_data\n",
        "if os.path.exists('hecktor2022_endpoint_training.csv'):\n",
        "  print('Survival data already uploaded')\n",
        "else:\n",
        "  uploaded = files.upload()"
      ],
      "metadata": {
        "id": "8Sbz8K7rmk27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the data\n",
        "features_df = load_features(folder_path='./', file_start=\"features_album\")\n",
        "pivoted_df = preprocess_data(features_df, prefixes=['original_intensity'])\n",
        "survival_df = pd.read_csv('hecktor2022_endpoint_training.csv')"
      ],
      "metadata": {
        "id": "Lgig9UuXmmaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter patients if not present in features or survival data\n",
        "deleted_from_survival = set(survival_df['PatientID']) - set(pivoted_df['PatientID'])\n",
        "deleted_from_pivoted = set(pivoted_df['PatientID']) - set(survival_df['PatientID'])\n",
        "\n",
        "print(\"Deleted patients from survival_df:\", len(deleted_from_survival), deleted_from_survival)\n",
        "print(\"Deleted patients from pivoted_df:\", len(deleted_from_pivoted), deleted_from_pivoted)\n",
        "\n",
        "# Drop rows\n",
        "pivoted_df = pivoted_df[pivoted_df['PatientID'].isin(survival_df['PatientID'])]\n",
        "survival_df = survival_df[survival_df['PatientID'].isin(pivoted_df['PatientID'])]"
      ],
      "metadata": {
        "id": "Yy3GTzknmoDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for training\n",
        "X = pivoted_df.drop(columns=['PatientID'])\n",
        "X = X.fillna(X.mean())\n",
        "y = np.array([(status, time) for status, time in zip(survival_df['Relapse'], survival_df['RFS'])],\n",
        "                dtype=[('event', 'bool'), ('time', 'float')])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model = RandomSurvivalForest(n_estimators=100, min_samples_split=10, min_samples_leaf=15, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "cindex_train = concordance_index_censored(y_train['event'], y_train['time'], model.predict(X_train))[0]\n",
        "cindex_test = concordance_index_censored(y_test['event'], y_test['time'], model.predict(X_test))[0]\n",
        "\n",
        "print(f'Concordance Index (Train): {cindex_train:.2f}')\n",
        "print(f'Concordance Index (Test): {cindex_test:.2f}')"
      ],
      "metadata": {
        "id": "EzOXlV2DmrzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train another model only with clinical info and compare them statistically\n",
        "pivoted_df = preprocess_data(features_df, prefixes=['original_glcm'])\n",
        "\n",
        "# Prepare data for training\n",
        "X2 = pivoted_df.drop(columns=['PatientID'])\n",
        "X2 = X.fillna(X2.mean())\n",
        "y = np.array([(status, time) for status, time in zip(survival_df['Relapse'], survival_df['RFS'])],\n",
        "                dtype=[('event', 'bool'), ('time', 'float')])\n",
        "X_train2, X_test2, y_train, y_test = train_test_split(X2, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model2 = RandomSurvivalForest(n_estimators=100, min_samples_split=10, min_samples_leaf=15, random_state=42)\n",
        "model2.fit(X_train2, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "cindex_train2 = concordance_index_censored(y_train['event'], y_train['time'], model2.predict(X_train2))[0]\n",
        "cindex_test2 = concordance_index_censored(y_test['event'], y_test['time'], model2.predict(X_test2))[0]\n",
        "\n",
        "print(f'Concordance Index (Train): {cindex_train2:.2f}')\n",
        "print(f'Concordance Index (Test): {cindex_test2:.2f}')"
      ],
      "metadata": {
        "id": "kf9n50MHmtcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Statistical test between the 2 models\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Function to calculate C-index\n",
        "def calculate_cindex(y_true, y_pred):\n",
        "    return concordance_index_censored(y_true['event'], y_true['time'], y_pred)[0]\n",
        "\n",
        "# Resample and compute differences\n",
        "def bootstrap_cindex_difference(X_test1, X_test2, y_test, model1, model2, n_iterations=1000):\n",
        "    differences = []\n",
        "    for _ in range(n_iterations):\n",
        "        X_resampled, y_resampled = resample(X_test1, y_test, random_state=_)\n",
        "        X_resampled2, y_resampled = resample(X_test2, y_test, random_state=_)\n",
        "        cindex1 = calculate_cindex(y_resampled, model1.predict(X_resampled))\n",
        "        cindex2 = calculate_cindex(y_resampled, model2.predict(X_resampled))\n",
        "        differences.append(cindex1 - cindex2)\n",
        "    return np.array(differences)\n",
        "\n",
        "# Compute the differences\n",
        "differences = bootstrap_cindex_difference(X_test, X_test2, y_test, model, model2)\n",
        "observed_diff = cindex_test - cindex_test2\n",
        "\n",
        "# Compute p-value\n",
        "p_value = np.mean(differences >= observed_diff)\n",
        "print(f'p-value: {p_value:.3f}')"
      ],
      "metadata": {
        "id": "iKGV0uYQmvIm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}